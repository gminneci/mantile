{
    "model_id": "meta-llama_Llama-3.1-405B-Instruct",
    "hf_model_id": "meta-llama/Llama-3.1-405B-Instruct",
    "name": "Llama 3.1 405B Instruct",
    "hidden_size": 16384,
    "num_layers": 126,
    "vocab_size": 128256,
    "total_params": 405853388800,
    "total_params_formatted": "405.9B",
    "layer_types": [
        {
            "name": "embedding",
            "class": "EmbeddingLayer",
            "count": 1,
            "supported": true,
            "specs": {
                "vocab_size": 128256,
                "hidden_size": 16384
            }
        },
        {
            "name": "attention",
            "class": "GroupedQueryAttentionLayer",
            "count": 126,
            "supported": true,
            "specs": {
                "hidden_size": 16384,
                "num_heads": 128,
                "num_kv_heads": 8,
                "head_dim": 128
            }
        },
        {
            "name": "mlp",
            "class": "GatedMLPLayer",
            "count": 126,
            "supported": true,
            "specs": {
                "hidden_size": 16384,
                "intermediate_size": 53248
            }
        },
        {
            "name": "norm",
            "class": "NormLayer",
            "count": 253,
            "supported": true,
            "specs": {
                "hidden_size": 16384,
                "has_bias": false
            }
        },
        {
            "name": "output",
            "class": "EmbeddingLayer",
            "count": 1,
            "supported": true,
            "specs": {
                "vocab_size": 128256,
                "hidden_size": 16384
            }
        }
    ],
    "validated": true,
    "validation_notes": "Manually verified against Meta Llama 3.1 Technical Report. Parameter count (405.9B) matches published figures. Layer mapping confirmed against internal Mantile layer classes.",
    "validation_sources": [
        "https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct",
        "https://ai.meta.com/blog/meta-llama-3-1/"
    ]
}